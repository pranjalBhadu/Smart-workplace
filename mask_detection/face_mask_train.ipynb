{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6d39d8-3614-49a0-a82b-f6b55b95b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc62830a-3553-4665-acb6-7d6a84c70da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (9.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8a385a-bf1c-4e5d-ba9a-9b054fefb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b569e5c-f3ca-458f-b0e5-eed1153b1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r\"/Users/pranjalbhadu/Documents/smart-workplace/mask_detection/Face_Mask_Dataset/Train\"\n",
    "CATEGORIES = [\"WithMask\", \"WithoutMask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a080d19-045a-4a17-a564-a79a89e2f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca63bb2-b334-40b2-95df-5e317dad1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1773a058-737a-4973-b24d-290e4691fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pil\n"
     ]
    }
   ],
   "source": [
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        try:\n",
    "            image=load_img(img_path, target_size=(224, 224))\n",
    "            image = img_to_array(image)\n",
    "            image = preprocess_input(image)\n",
    "            data.append(image)\n",
    "            labels.append(category)\n",
    "        except PIL.UnidentifiedImageError:\n",
    "                print('pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2e581f-e054-4bdd-8602-ad4f44475afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WithMask', 'WithMask', 'WithMask', 'WithMask', 'WithMask']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e4e3ce9-8de2-42b2-9cf7-6bb09ddccad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "494409d4-6bc2-46ee-a1ef-b164bd166fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0275f43-1494-4113-b4f3-92ef02715b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = data\n",
    "trainY = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "902049dd-f118-4929-81c8-828ce8f49d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "test_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c3809ce-9edb-4309-915f-3ebf432a88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIRECTORY = r\"/Users/pranjalbhadu/Documents/smart-workplace/mask_detection/Face_Mask_Dataset/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "976a4c25-5254-4235-a79b-9f285f30d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in CATEGORIES:\n",
    "    path = os.path.join(TEST_DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        try:\n",
    "            image=load_img(img_path, target_size=(224, 224))\n",
    "            image = img_to_array(image)\n",
    "            image = preprocess_input(image)\n",
    "            test_data.append(image)\n",
    "            test_labels.append(category)\n",
    "        except PIL.UnidentifiedImageError:\n",
    "                print('pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dadfc928-261b-407f-95ca-815c42768898",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = lb.fit_transform(test_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33221129-2410-467f-aaeb-6056fa19b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.array(test_data, dtype=\"float32\")\n",
    "testY = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7c4f1a4-fde3-4768-b1eb-2ad64379a30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c477008-a107-4551-bb90-4b200972df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 09:51:45.658859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89f7fbc7-f50a-4ed7-9519-1ae0df7eddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f9ea6a914f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50ba8399-bd30-46b4-8e1f-5d217f85b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bea9501-ff90-445c-a2d5-b61aa372c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f3cba7f-e69a-4829-8ce7-0bc0f5af3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b07d4d0f-16c7-4b86-a411-15375fb03c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0874d987-422c-4c21-8553-ba379f360b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testY)//BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b05be735-0ad7-475f-a832-3536d2563b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce4021d9-2c45-4bc4-945d-2b7bc255ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ad3b32f-3b57-43f2-ae75-c5876372a017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "538/538 [==============================] - 341s 633ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.0198 - val_accuracy: 0.9940\n",
      "Epoch 2/5\n",
      "538/538 [==============================] - 396s 737ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0168 - val_accuracy: 0.9950\n",
      "Epoch 3/5\n",
      "538/538 [==============================] - 423s 787ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0141 - val_accuracy: 0.9970\n",
      "Epoch 4/5\n",
      "538/538 [==============================] - 387s 720ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0133 - val_accuracy: 0.9970\n",
      "Epoch 5/5\n",
      "538/538 [==============================] - 375s 697ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0137 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainX, trainY, batch_size=BS,\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=5,  callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0b6aa0f-855d-4850-9e50-f7c7eed7f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 19s 579ms/step\n"
     ]
    }
   ],
   "source": [
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "676eb27f-0a3e-4be0-a575-2664186ecd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fac31989-822a-45e7-929b-07645c13b903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    WithMask       0.99      1.00      0.99       483\n",
      " WithoutMask       1.00      0.99      1.00       509\n",
      "\n",
      "    accuracy                           0.99       992\n",
      "   macro avg       0.99      1.00      0.99       992\n",
      "weighted avg       0.99      0.99      0.99       992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4fbc3dfc-ccad-4dd1-a6e5-7660b63d54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mask_detector.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bbef6-816a-4aa1-b628-e20f6983c223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
